{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this experiment  you need to have your own csv containing types of questions that users can\n",
    "ask or ask the AI team to for their dataset as we did not upload the csv to this repo\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T17:37:59.486991Z",
     "start_time": "2026-02-19T17:37:59.385229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from ai_docs_filterer_for_RAG import run_rm_labeller\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from openai import AsyncAzureOpenAI\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from ccs_website_data import  fetch_all_ccs_frameworks\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "f5d0727b303dafd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T17:41:28.079312Z",
     "start_time": "2026-02-19T17:41:27.078171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data = pd.read_csv(\"query_filter_questions.csv\")\n",
    "ccs_frameworks = fetch_all_ccs_frameworks()\n",
    "pydantic_azure_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_deployment=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "pydantic_rm_labeller_model = OpenAIChatModel(\n",
    "    model_name= os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    provider=OpenAIProvider(openai_client=pydantic_azure_client)\n",
    ")\n",
    "\n",
    "rm_descriptions = \"\\n\".join([\n",
    "    f\"RM: {r.rm_number} | \"\n",
    "    f\"Keywords: {r.keywords if 'keywords' in r and str(r.keywords).strip() else 'N/A'} | \"\n",
    "    f\"Summary: {r.summary} | \"\n",
    "    f\"Pillar: {r.pillar} ({r.category})\"\n",
    "    for _, r in ccs_frameworks.iloc[:20].iterrows()# get only first 20\n",
    "])\n"
   ],
   "id": "c88452e77300c091",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fetch and clean frameworks (Status: Live,Expired)...\n",
      "Fetched Page 1. Total frameworks collected: 268\n",
      "Finished. Reached the last page: 1.\n",
      "\n",
      "âœ… DataFrame created successfully!\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Running experiment",
   "id": "4c928247614306f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T17:46:40.807449Z",
     "start_time": "2026-02-19T17:46:40.799113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def process_dataframe(df):\n",
    "    # 1. Create the list of coroutines\n",
    "    # We add a small helper here to extract .rm_number after the await\n",
    "    async def get_label(query_text):\n",
    "        result = await run_rm_labeller(pydantic_rm_labeller_model, rm_descriptions, query_text)\n",
    "        return result.rm_number # Extracting the specific field from Pydantic\n",
    "\n",
    "    # 2. Build the task list\n",
    "    tasks = [get_label(row['query']) for _, row in df.iterrows()]\n",
    "\n",
    "    # 3. Run concurrently\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # 4. Assign results to the dataframe\n",
    "    df['predicted_rm'] = results\n",
    "    return df"
   ],
   "id": "b08348b907cdcb72",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T17:47:45.659762Z",
     "start_time": "2026-02-19T17:46:42.653296Z"
    }
   },
   "cell_type": "code",
   "source": "result_df = await process_dataframe(test_data)",
   "id": "cdb10347c5bdd016",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T17:47:45.716735Z",
     "start_time": "2026-02-19T17:47:45.707706Z"
    }
   },
   "cell_type": "code",
   "source": "print(result_df[\"predicted_rm\"])",
   "id": "1f7ad4717e870ac1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     RM6348\n",
      "1     RM6348\n",
      "2     RM6348\n",
      "3     RM6348\n",
      "4     RM6348\n",
      "       ...  \n",
      "90    RM6111\n",
      "91    RM6111\n",
      "92    RM6292\n",
      "93    RM6111\n",
      "94    RM6292\n",
      "Name: predicted_rm, Length: 95, dtype: object\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T17:48:41.854475Z",
     "start_time": "2026-02-19T17:48:41.843990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate accuracy as a decimal (e.g., 0.85)\n",
    "accuracy = (result_df['Truth Set'] == result_df['predicted_rm']).mean()\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "id": "8a86f319a68a79a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 82.11%\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
